{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b41547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting names\n",
      "  Downloading names-0.3.0.tar.gz (789 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: names\n",
      "  Building wheel for names (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for names: filename=names-0.3.0-py3-none-any.whl size=803699 sha256=c87ba487fee19952390ecc026650f72457349c0045d738c19959cba4750d4ac0\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/35/f7/c72132a4f3878b82018a3e61bf2a35e6b63cebe1dd9f72ec1e\n",
      "Successfully built names\n",
      "Installing collected packages: names\n",
      "Successfully installed names-0.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b679a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REPEATER 0\n",
      "------------------------\n",
      "iteration 1. 102 items to process.\n",
      "iteration 2. 102 items to process.\n",
      "iteration 3. 102 items to process.\n",
      "iteration 4. 102 items to process.\n",
      "iteration 5. 21 items to process.\n",
      "iteration 6. 17 items to process.\n",
      "\n",
      "REPEATER 1\n",
      "------------------------\n",
      "iteration 1. 100 items to process.\n",
      "iteration 2. 100 items to process.\n",
      "iteration 3. 100 items to process.\n",
      "iteration 4. 100 items to process.\n",
      "iteration 5. 34 items to process.\n",
      "iteration 6. 26 items to process.\n",
      "\n",
      "REPEATER 2\n",
      "------------------------\n",
      "iteration 1. 100 items to process.\n",
      "iteration 2. 100 items to process.\n",
      "iteration 3. 100 items to process.\n",
      "iteration 4. 100 items to process.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import json\n",
    "from random import choice, randint, random\n",
    "\n",
    "import names\n",
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "from shinewave_webapp.database_connector import get_conn, get_random_key, run_query\n",
    "\n",
    "\n",
    "FIRST_NAME_LIST = [names.get_first_name() for i in range(500)]\n",
    "LAST_NAME_LIST = [names.get_last_name() for i in range(500)]\n",
    "NODES = run_query('SELECT DISTINCT object_id FROM workflow_nodes', return_data_format=dict)\n",
    "NODE_WEIGHTS = {object_id: random() for object_id in NODES['object_id']}\n",
    "\n",
    "\n",
    "def add_progression_event(\n",
    "    event_id,\n",
    "    node_master_type,\n",
    "    node_parent_type,\n",
    "    node_detail_type,\n",
    "    recipient_id,\n",
    "    current_node_time,\n",
    "    added_days,\n",
    "    added_minutes,\n",
    "    workflow_node_id\n",
    "):\n",
    "    run_query(\n",
    "        \"\"\"\n",
    "            INSERT INTO events (id, event_type, event_subtype, recipient_id, event_time, workflow_node_id, custom_data)\n",
    "            VALUES (?, ?, ?, ?, ?::TIMESTAMP + INTERVAL '? DAYS' + INTERVAL '? MINUTES', ?, '{}')\n",
    "        \"\"\",\n",
    "        sql_parameters=[\n",
    "            event_id,\n",
    "            f'{node_master_type}.{node_parent_type}',\n",
    "            node_detail_type,\n",
    "            recipient_id,\n",
    "            current_node_time,\n",
    "            added_days,\n",
    "            added_minutes,\n",
    "            workflow_node_id\n",
    "        ],\n",
    "        commit=True\n",
    "    )\n",
    "    \n",
    "\n",
    "def add_outreach_entry(\n",
    "    workflow_id,\n",
    "    current_id,\n",
    "    recipient_id,\n",
    "    workflow_node_id,\n",
    "    current_node_time,\n",
    "    added_days,\n",
    "    pending_triggers,\n",
    "    pending_outreaches,\n",
    "    pending_markers,\n",
    "    active\n",
    "):\n",
    "    if not isinstance(pending_triggers, str):\n",
    "        pending_triggers = json.dumps(pending_triggers)\n",
    "    if not isinstance(pending_outreaches, str):\n",
    "        pending_outreaches = json.dumps(pending_outreaches)\n",
    "    if not isinstance(pending_markers, str):\n",
    "        pending_markers = json.dumps(pending_markers)\n",
    "\n",
    "    run_query(\n",
    "        \"\"\"\n",
    "            INSERT INTO outreach_lists (\n",
    "                id,\n",
    "                account_id,\n",
    "                workflow_id,\n",
    "                source_event_id,\n",
    "                recipient_id,\n",
    "                current_node_id,\n",
    "                current_node_time,\n",
    "                pending_triggers,\n",
    "                pending_outreaches,\n",
    "                pending_markers,\n",
    "                active\n",
    "            )\n",
    "            VALUES (\n",
    "                (SELECT MAX(id) + 1 FROM outreach_lists), -- id\n",
    "                1, -- account_id\n",
    "                ?, -- workflow_id\n",
    "                ?, -- source_event_id\n",
    "                ?, -- recipient_id\n",
    "                ?, -- current_node_id\n",
    "                ?::TIMESTAMP + INTERVAL '? DAYS', -- current_node_time\n",
    "                ?, -- pending_triggers\n",
    "                ?, -- pending_outreaches\n",
    "                ?, -- pending_markers\n",
    "                ? -- active\n",
    "            )\n",
    "        \"\"\",\n",
    "        sql_parameters=[\n",
    "            workflow_id,\n",
    "            current_id,\n",
    "            recipient_id,\n",
    "            workflow_node_id,\n",
    "            current_node_time,\n",
    "            added_days,\n",
    "            pending_triggers,\n",
    "            pending_outreaches,\n",
    "            pending_markers,\n",
    "            active\n",
    "        ],\n",
    "        commit=True\n",
    "    )\n",
    "    \n",
    "\n",
    "def deactivate_outreach_list(outreach_list_id):\n",
    "    run_query(\n",
    "        \"UPDATE outreach_lists SET active = 'FALSE' WHERE id = ?\",\n",
    "        sql_parameters=[outreach_list_id],\n",
    "        commit=True\n",
    "    )\n",
    "\n",
    "\n",
    "def get_node_data(workflow_id, object_id):\n",
    "    next_node_data = run_query(\n",
    "        \"\"\"\n",
    "            SELECT\n",
    "                id,\n",
    "                node_type,\n",
    "                outputs AS pending_nodes\n",
    "            FROM workflow_nodes\n",
    "            WHERE\n",
    "                workflow_id = ?\n",
    "                AND object_id = ?\n",
    "                AND UPPER(active) = 'TRUE'\n",
    "        \"\"\",\n",
    "        sql_parameters=[workflow_id, object_id],\n",
    "        return_data_format=dict\n",
    "    )\n",
    "    \n",
    "    workflow_node_id = next_node_data['id'][0]\n",
    "    node_type = next_node_data['node_type'][0]\n",
    "    pending_nodes = json.loads(next_node_data['pending_nodes'][0])\n",
    "    \n",
    "    return (workflow_node_id, node_type, pending_nodes)\n",
    "    \n",
    "\n",
    "def progress_outreach(outreach_list_id, node_weights=NODE_WEIGHTS):\n",
    "    current_state = run_query(\n",
    "        \"\"\"\n",
    "            SELECT\n",
    "                workflow_id,\n",
    "                recipient_id,\n",
    "                current_node_id IS NULL AS is_entry_node,\n",
    "                current_node_time,\n",
    "                pending_triggers,\n",
    "                pending_outreaches,\n",
    "                pending_markers\n",
    "            FROM outreach_lists\n",
    "            WHERE id = ? AND UPPER(active) = 'TRUE'\n",
    "        \"\"\",\n",
    "        sql_parameters=[outreach_list_id],\n",
    "        return_data_format=dict\n",
    "    )\n",
    "    try:\n",
    "        workflow_id = current_state['workflow_id'][0]\n",
    "    except:\n",
    "        return False\n",
    "    is_entry_node = current_state['is_entry_node'][0]\n",
    "    recipient_id = current_state['recipient_id'][0]\n",
    "    current_node_time = current_state['current_node_time'][0]\n",
    "    pending_triggers = json.loads(current_state['pending_triggers'][0])\n",
    "    pending_outreaches = json.loads(current_state['pending_outreaches'][0])\n",
    "    pending_markers = json.loads(current_state['pending_markers'][0])\n",
    "    \n",
    "    if pending_markers:\n",
    "        for node in pending_markers:\n",
    "            workflow_node_id, node_type, null = get_node_data(workflow_id, node)\n",
    "\n",
    "            node_master_type, node_parent_type, node_detail_type = node_type.split('.')\n",
    "            current_id = run_query(\"SELECT COALESCE(MAX(id), 0) FROM events\")[0][0] + 1\n",
    "\n",
    "            add_progression_event(\n",
    "                current_id,\n",
    "                node_master_type,\n",
    "                node_parent_type,\n",
    "                node_detail_type,\n",
    "                recipient_id,\n",
    "                current_node_time,\n",
    "                0,\n",
    "                0,\n",
    "                workflow_node_id\n",
    "            )\n",
    "\n",
    "            add_outreach_entry(\n",
    "                workflow_id,\n",
    "                current_id,\n",
    "                recipient_id,\n",
    "                workflow_node_id,\n",
    "                current_node_time,\n",
    "                0,\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                'FALSE'\n",
    "            )\n",
    "    \n",
    "    if pending_outreaches:\n",
    "        next_node = pending_outreaches[0]\n",
    "        added_days = 0\n",
    "        added_minutes = randint(0, 10)\n",
    "\n",
    "    elif pending_triggers:\n",
    "        if (not is_entry_node) and (random() < .1):\n",
    "            pending_trigger_node_types = run_query(\n",
    "                \"\"\"\n",
    "                    SELECT node_type\n",
    "                    FROM workflow_nodes\n",
    "                    WHERE\n",
    "                        workflow_id = ?\n",
    "                        AND object_id IN ?\n",
    "                        AND UPPER(active) = 'TRUE'\n",
    "                \"\"\",\n",
    "                sql_parameters=[workflow_id, tuple(pending_triggers)],\n",
    "                return_data_format=dict\n",
    "            )\n",
    "            if not 'nodes.trigger.TimeElapsedTrigger' in pending_trigger_node_types['node_type']:\n",
    "                deactivate_outreach_list(outreach_list_id)\n",
    "                return True\n",
    "\n",
    "        node_weights = [node_weights[i] for i in pending_triggers]\n",
    "        node_weights = [i/sum(node_weights) for i in node_weights]\n",
    "        next_node = numpy.random.choice(pending_triggers, 1, p=node_weights)[0]\n",
    "        added_days = randint(1, 8)\n",
    "        added_minutes = 0\n",
    "    \n",
    "    workflow_node_id, node_type, pending_nodes = get_node_data(workflow_id, next_node)\n",
    "\n",
    "    if pending_nodes:\n",
    "        pending_node_data = run_query(\n",
    "            \"\"\"\n",
    "                SELECT\n",
    "                    object_id,\n",
    "                    node_type\n",
    "                FROM workflow_nodes\n",
    "                WHERE\n",
    "                    workflow_id = ?\n",
    "                    AND object_id IN ?\n",
    "                    AND UPPER(active) = 'TRUE'\n",
    "            \"\"\",\n",
    "            sql_parameters=[workflow_id, tuple(pending_nodes)],\n",
    "            return_data_format=dict\n",
    "        )\n",
    "\n",
    "        pending_node_data = list(zip(pending_node_data['object_id'], pending_node_data['node_type']))\n",
    "        pending_triggers = [\n",
    "            object_id for object_id, node_type in pending_node_data if node_type.startswith('nodes.trigger')\n",
    "        ]\n",
    "        pending_outreaches = [\n",
    "            object_id for object_id, node_type in pending_node_data if node_type.startswith('nodes.outreach')\n",
    "        ]\n",
    "        pending_markers = [\n",
    "            object_id for object_id, node_type in pending_node_data if node_type.startswith('nodes.marker')\n",
    "        ]\n",
    "        active = 'TRUE'\n",
    "    else:\n",
    "        pending_triggers = pending_outreaches = pending_markers = []\n",
    "        active = 'FALSE'\n",
    "\n",
    "    node_master_type, node_parent_type, node_detail_type = node_type.split('.')\n",
    "    \n",
    "    current_id = run_query(\"SELECT COALESCE(MAX(id), 0) FROM events\")[0][0] + 1\n",
    "\n",
    "    add_progression_event(\n",
    "        current_id,\n",
    "        node_master_type,\n",
    "        node_parent_type,\n",
    "        node_detail_type,\n",
    "        recipient_id,\n",
    "        current_node_time,\n",
    "        added_days,\n",
    "        added_minutes,\n",
    "        workflow_node_id\n",
    "    )\n",
    "    \n",
    "    add_outreach_entry(\n",
    "        workflow_id,\n",
    "        current_id,\n",
    "        recipient_id,\n",
    "        workflow_node_id,\n",
    "        current_node_time,\n",
    "        added_days,\n",
    "        pending_triggers,\n",
    "        pending_outreaches,\n",
    "        pending_markers,\n",
    "        active\n",
    "    )\n",
    "    \n",
    "    deactivate_outreach_list(outreach_list_id)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def generate_drug():\n",
    "    prefixes = [\n",
    "        'Lorem',\n",
    "        'Ipsum',\n",
    "        'Dolor',\n",
    "        'Sit',\n",
    "        'Amet',\n",
    "        'Elit',\n",
    "        'Sed',\n",
    "        'Do',\n",
    "        'Eiusmod',\n",
    "        'Tempor'\n",
    "    ]\n",
    "    suffixes = [\n",
    "        'afil',\n",
    "        'asone',\n",
    "        'bicin',\n",
    "        'bital',\n",
    "        'caine',\n",
    "        'cillin',\n",
    "        'cycline',\n",
    "        'dazole',\n",
    "        'dipine',\n",
    "        'dronate',\n",
    "        'eprazole',\n",
    "        'fenac',\n",
    "        'floxacin',\n",
    "        'gliptin',\n",
    "        'glitazone',\n",
    "        'iramine',\n",
    "        'lamide',\n",
    "        'mab',\n",
    "        'mustine',\n",
    "        'mycin',\n",
    "        'nacin',\n",
    "        'nazole',\n",
    "        'olol',\n",
    "        'olone',\n",
    "        'onide',\n",
    "        'oprazole',\n",
    "        'phylline',\n",
    "        'pramine',\n",
    "        'pril',\n",
    "        'profen',\n",
    "        'ridone',\n",
    "        'sartan',\n",
    "        'semide',\n",
    "        'setron',\n",
    "        'statin',\n",
    "        'tadine',\n",
    "        'tadine',\n",
    "        'terol',\n",
    "        'thiazide',\n",
    "        'tinib',\n",
    "        'trel',\n",
    "        'triptan',\n",
    "        'tyline',\n",
    "        'vir',\n",
    "        'vir',\n",
    "        'vir',\n",
    "        'vudine',\n",
    "        'zepam',\n",
    "        'zodone',\n",
    "        'zolam',\n",
    "        'zosin'\n",
    "    ]\n",
    "    \n",
    "    return choice(prefixes) + choice(suffixes)\n",
    "\n",
    "\n",
    "def generate_members_data(number_of_rows, starting_id=5, first_name_list=FIRST_NAME_LIST, last_name_list=LAST_NAME_LIST):\n",
    "    rows = []\n",
    "    member_id = starting_id\n",
    "    for i in range(number_of_rows):\n",
    "        provider_id = get_random_key([])[:11]\n",
    "        phone_number = int(''.join([str(randint(0, 9)) for i in range(10)]))\n",
    "        first_name = choice(first_name_list)\n",
    "        last_name = choice(last_name_list)\n",
    "        email_address = f'{first_name}.{last_name}@test.com'\n",
    "\n",
    "        prescription_1 = generate_drug()\n",
    "        prescription_2 = [generate_drug(), ''][randint(0, 1)]\n",
    "        custom_data = {'prescription_1': prescription_1, 'prescription_2': prescription_2}\n",
    "        custom_data = json.dumps(custom_data)\n",
    "\n",
    "        key_date = None\n",
    "        while key_date is None:\n",
    "            try:\n",
    "                key_date = datetime(randint(2021, 2022), randint(1,12), randint(1, 31))\n",
    "                key_date = str(key_date).split(' ')[0]\n",
    "            except:\n",
    "                key_date = None\n",
    "\n",
    "        key_hour = '{:02d}'.format(randint(0, 23))\n",
    "        key_minute = '{:02d}'.format(randint(0, 59))\n",
    "        key_time = f'{key_hour}:{key_minute}:00'\n",
    "        row = [\n",
    "            member_id,\n",
    "            1,\n",
    "            provider_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            phone_number,\n",
    "            email_address,\n",
    "            key_date,\n",
    "            key_time,\n",
    "            'US/Pacific',\n",
    "            None,\n",
    "            None,\n",
    "            custom_data,\n",
    "            True\n",
    "        ]\n",
    "        member_id += 1\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "def generate_lists_data(starting_id=0):\n",
    "    def _val_to_json(val):\n",
    "        if val:\n",
    "            return json.dumps(val.split(','))\n",
    "        else:\n",
    "            return json.dumps([])\n",
    "\n",
    "    recipients = run_query(\n",
    "        f\"\"\"\n",
    "            WITH base_data AS (\n",
    "                SELECT\n",
    "                    ROW_NUMBER() OVER (PARTITION BY NULL ORDER BY NULL) - 1 + {starting_id} AS id,\n",
    "                    account_id,\n",
    "                    2 AS workflow_id,\n",
    "                    NULL AS source_event_id,\n",
    "                    id AS recipient_id,\n",
    "                    NULL AS current_node_id,\n",
    "                    '2021-01-01 10:00'::TIMESTAMP AS current_node_time,\n",
    "                    NULL AS pending_triggers,\n",
    "                    TRUE as active\n",
    "                FROM recipients\n",
    "                WHERE\n",
    "                    account_id = 1\n",
    "                    AND active\n",
    "            )\n",
    "            SELECT\n",
    "                bd.*,\n",
    "                STRING_AGG(wn1.object_id, ',') AS pending_triggers,\n",
    "                STRING_AGG(wn2.object_id, ',') AS pending_outreaches,\n",
    "                STRING_AGG(wn3.object_id, ',') AS pending_markers\n",
    "            FROM base_data bd\n",
    "            LEFT JOIN workflow_nodes wn1 ON\n",
    "                bd.workflow_id = wn1.workflow_id\n",
    "                AND wn1.active = 'TRUE'\n",
    "                AND wn1.inputs = '[]'\n",
    "                AND wn1.node_type LIKE ?\n",
    "            LEFT JOIN workflow_nodes wn2 ON\n",
    "                bd.workflow_id = wn2.workflow_id\n",
    "                AND wn2.active = 'TRUE'\n",
    "                AND wn2.inputs = '[]'\n",
    "                AND wn2.node_type LIKE ?\n",
    "            LEFT JOIN workflow_nodes wn3 ON\n",
    "                bd.workflow_id = wn3.workflow_id\n",
    "                AND wn3.active = 'TRUE'\n",
    "                AND wn3.inputs = '[]'\n",
    "                AND wn3.node_type LIKE ?\n",
    "            LEFT JOIN outreach_lists ol ON\n",
    "                bd.recipient_id = ol.recipient_id\n",
    "                AND bd.workflow_id = ol.workflow_id\n",
    "            WHERE ol.id IS NULL\n",
    "            GROUP BY\n",
    "                bd.id,\n",
    "                bd.account_id,\n",
    "                bd.workflow_id,\n",
    "                bd.source_event_id,\n",
    "                bd.recipient_id,\n",
    "                bd.current_node_id,\n",
    "                bd.current_node_time,\n",
    "                bd.pending_triggers,\n",
    "                bd.active\n",
    "        \"\"\",\n",
    "        return_data_format=dict,\n",
    "        sql_parameters=['nodes.trigger%', 'nodes.outreach%', 'nodes.marker%']\n",
    "    )\n",
    "    \n",
    "    recipients_df = pd.DataFrame(recipients)\n",
    "    recipients_df['pending_triggers'] = recipients_df['pending_triggers'].map(_val_to_json)\n",
    "    recipients_df['pending_outreaches'] = recipients_df['pending_outreaches'].map(_val_to_json)\n",
    "    recipients_df['pending_markers'] = recipients_df['pending_markers'].map(_val_to_json)\n",
    "    return recipients_df\n",
    "\n",
    "for repeater in range(100):\n",
    "    print(f'\\nREPEATER {repeater}\\n------------------------')\n",
    "    table_gen_dict = OrderedDict({\n",
    "        'recipients': {'gen_fn': generate_members_data, 'args': [100]}\n",
    "    })\n",
    "\n",
    "    for table_name, details in table_gen_dict.items():\n",
    "\n",
    "        starting_id = run_query(\n",
    "            f\"SELECT MAX(id) FROM {table_name}\",\n",
    "            return_data_format=list\n",
    "        )[0][0] or 0\n",
    "\n",
    "        starting_id += 1\n",
    "\n",
    "        gen_func = details['gen_fn']\n",
    "        args = details.get('args', [])\n",
    "        results = gen_func(*args, starting_id=starting_id)\n",
    "        table_gen_dict[table_name]['results'] = results\n",
    "\n",
    "    for table_name, details in table_gen_dict.items():\n",
    "        rows = []\n",
    "        insert_statement = f\"INSERT INTO {table_name} VALUES\"\n",
    "        for row in details['results']:\n",
    "            insert_statement += '\\n    (' + ', '.join(['?' for i in row]) + '),'\n",
    "            rows += row\n",
    "        insert_statement = insert_statement[:-1]\n",
    "        run_query(insert_statement, sql_parameters=rows, commit=True)\n",
    "\n",
    "    df = generate_lists_data()\n",
    "    conn = get_conn()\n",
    "    df.to_sql('outreach_lists', conn, if_exists='append', index=False)\n",
    "    conn.close()\n",
    "\n",
    "    progress_id_list = list(chain(*run_query(\n",
    "        \"SELECT id FROM outreach_lists WHERE UPPER(active) = 'TRUE'\", return_data_format=list\n",
    "    )))\n",
    "\n",
    "    iteration = 0\n",
    "    while progress_id_list:\n",
    "        iteration += 1\n",
    "        if True: # iteration % 10 == 0 or iteration == 1:\n",
    "            print(f'iteration {iteration}. {len(progress_id_list)} items to process.')\n",
    "        [progress_outreach(i) for i in progress_id_list]\n",
    "        progress_id_list = list(chain(*run_query(\n",
    "            \"SELECT id FROM outreach_lists WHERE UPPER(active) = 'TRUE'\", return_data_format=list\n",
    "        )))\n",
    "\n",
    "    run_query(\"\"\"\n",
    "        SELECT pg_terminate_backend(pid) FROM pg_stat_activity\n",
    "        WHERE datname = 'shinewavebackend'\n",
    "        AND pid <> pg_backend_pid()\n",
    "        AND state in ('idle');\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c498c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
